<<<<<<< HEAD
if (length(y) != nrow(x)) {
stop("length of y and number of rows in x are different")
}
if (any(is.na(x))) {
stop("missing values are not allowed")
}
variables = colnames(x)    # extract variables names
nvar = length(variables)   # count number of variables
## set global parameters
if (is.null(mtry)) {
mtry = floor((nvar)^(3/4))
}
if (mtry == "sqrt") {
mtry = floor(sqrt(nvar))
}
if (mtry == "0.5") {
mtry = floor(0.5*nvar)
}
if (mtry == "^3/4") {
mtry = floor((nvar)^(3/4))
}
if (is.null(s)) {
s = ceiling(nvar*0.01)
}
if (s > (nvar - 1)) {
s = nvar - 1
warning("s was set to the maximum number that is reasonable (variables-1) ")
}
if (type == "classification") {
y = as.factor(y)
if (length(levels(y)) > 15) {
stop("Too much classes defined, classification might be the wrong choice")
}
}
if (type == "regression" && class(y) == "factor") {
stop("use factor variable for y only for classification! ")
}
data = data.frame(y, x)
type = classification
type = "classification"
## check data
if (length(y) != nrow(x)) {
stop("length of y and number of rows in x are different")
}
if (any(is.na(x))) {
stop("missing values are not allowed")
}
variables = colnames(x)    # extract variables names
nvar = length(variables)   # count number of variables
## set global parameters
if (is.null(mtry)) {
mtry = floor((nvar)^(3/4))
}
if (mtry == "sqrt") {
mtry = floor(sqrt(nvar))
}
if (mtry == "0.5") {
mtry = floor(0.5*nvar)
}
if (mtry == "^3/4") {
mtry = floor((nvar)^(3/4))
}
if (is.null(s)) {
s = ceiling(nvar*0.01)
}
if (s > (nvar - 1)) {
s = nvar - 1
warning("s was set to the maximum number that is reasonable (variables-1) ")
}
if (type == "classification") {
y = as.factor(y)
if (length(levels(y)) > 15) {
stop("Too much classes defined, classification might be the wrong choice")
}
}
if (type == "regression" && class(y) == "factor") {
stop("use factor variable for y only for classification! ")
}
data = data.frame(y, x)
RF = ranger::ranger(data = data,dependent.variable.name = "y",num.trees = ntree,mtry = mtry,min.node.size = min.node.size,
keep.inbag = TRUE, num.threads = num.threads, case.weights = case.weights, respect.unordered.factors = "partition")
mtry
=======
>>>>>>> 8a71999afb43d79f0113d47d9734af6e63de6c1d
mtry = 5
RF = ranger::ranger(data = data,dependent.variable.name = "y",num.trees = ntree,mtry = mtry,min.node.size = min.node.size,
keep.inbag = TRUE, num.threads = num.threads, case.weights = case.weights, respect.unordered.factors = "partition")
trees = getTreeranger(RF = RF,ntree = ntree)
trees[[1]]
trees.lay = addLayer(trees)
rm(trees)
###AddSurrogates###
trees.surr = addSurrogates(RF = RF,trees = trees.lay,s = s,Xdata = x, num.threads = num.threads)
library(SurrogateMinimalDepth)
library("SurrogateMinimalDepth")
library("ranger")
data("SMD_example_data")
class = c(rep(1,50),rep(0,50))
restvar = SMD_example_data[,184:200]
var.1 = c(rep("A",25),rep("B",25),rep("C",25),rep("D",25))
var.2 = c(rep("C",25),rep("A",25),rep("D",25),rep("B",25))
#erste variable
var.1[c(9,13,17,24)] = "C"
var.1[c(3,4)] = "D"
var.1[c(6)] = "B"
var.2[c(9,13,17,24)] = "D"
var.2[c(3,4)] = "B"
var.2[c(6)] = "A"
#zweite variable
var.1[c(27,33,38,41,44)] = "C"
var.1[30] = "D"
var.1[c(35,48)] = "A"
var.2[c(27,33,38,41,44)] = "D"
var.2[30] = "B"
var.2[c(35,48)] = "C"
#dritte variable
var.1[c(59,63,67,74)] = "A"
var.1[c(53,54)] = "B"
var.1[56] = "D"
var.2[c(59,63,67,74)] = "C"
var.2[c(53,54)] = "A"
var.2[56] = "B"
#vierte variable
var.1[c(77,83,88,91,94)] = "C"
var.1[80] = "B"
var.1[c(85,98)] = "A"
var.2[c(27,33,38,41,44)] = "D"
var.2[30] = "A"
var.2[c(35,48)] = "C"
testdata = cbind(var.1,var.2,var.1,restvar)
rownames(testdata) = paste0("sample_",c(1:100))
colnames(testdata) = paste0("variable_",c(1:20))
ntree = 50
RF = ranger(x=testdata, y=class, classification = TRUE, num.trees = ntree, respect.unordered.factors = "partition")
trees = getTreeranger(RF = RF,ntree = ntree)
set.seed(42)
res = var.relations(x = testdata,
y = class,
s = 9,
ntree = 1000,
t = 5,
create.forest = TRUE,
candidates = colnames(testdata),
variables = colnames(testdata),
type = "classification")
res$surr.res
## check data
if (length(y) != nrow(x)) {
stop("length of y and number of rows in x are different")
}
if (any(is.na(x))) {
stop("missing values are not allowed")
}
variables = colnames(x)    # extract variables names
nvar = length(variables)   # count number of variables
## set global parameters
if (is.null(mtry)) {
mtry = floor((nvar)^(3/4))
}
if (mtry == "sqrt") {
mtry = floor(sqrt(nvar))
}
if (mtry == "0.5") {
mtry = floor(0.5*nvar)
}
if (mtry == "^3/4") {
mtry = floor((nvar)^(3/4))
}
if (is.null(s)) {
s = ceiling(nvar*0.01)
}
if (s > (nvar - 1)) {
s = nvar - 1
warning("s was set to the maximum number that is reasonable (variables-1) ")
}
if (type == "classification") {
y = as.factor(y)
if (length(levels(y)) > 15) {
stop("Too much classes defined, classification might be the wrong choice")
}
}
if (type == "regression" && class(y) == "factor") {
stop("use factor variable for y only for classification! ")
}
data = data.frame(y, x)
library(SurrogateMinimalDepth)
# read data
data("SMD_example_data")
data = SMD_example_data
x = data[,2:ncol(data)]
y = data[,1]
ntree = 10
type = "regression"
s = 10
mtry = NULL
min.node.size = 1
num.threads = NULL
status = NULL
save.ranger = FALSE
create.forest = TRUE
forest = NULL
save.memory = FALSE
min.var.p = 200
p.t.sel = 0.01
p.t.rel = 0.01
select.var = TRUE
case.weights = NULL
variables = c("X1","X7")
candidates = colnames(x)[1:100]
## check data
if (length(y) != nrow(x)) {
stop("length of y and number of rows in x are different")
}
if (any(is.na(x))) {
stop("missing values are not allowed")
}
variables = colnames(x)    # extract variables names
nvar = length(variables)   # count number of variables
## set global parameters
if (is.null(mtry)) {
mtry = floor((nvar)^(3/4))
}
if (mtry == "sqrt") {
mtry = floor(sqrt(nvar))
}
if (mtry == "0.5") {
mtry = floor(0.5*nvar)
}
if (mtry == "^3/4") {
mtry = floor((nvar)^(3/4))
}
if (is.null(s)) {
s = ceiling(nvar*0.01)
}
if (s > (nvar - 1)) {
s = nvar - 1
warning("s was set to the maximum number that is reasonable (variables-1) ")
}
if (type == "classification") {
y = as.factor(y)
if (length(levels(y)) > 15) {
stop("Too much classes defined, classification might be the wrong choice")
}
}
if (type == "regression" && class(y) == "factor") {
stop("use factor variable for y only for classification! ")
}
data = data.frame(y, x)
RF = ranger::ranger(data = data,dependent.variable.name = "y",num.trees = ntree,mtry = mtry,min.node.size = min.node.size,
keep.inbag = TRUE, num.threads = num.threads, case.weights = case.weights, respect.unordered.factors = "partition")
trees = getTreeranger(RF = RF,ntree = ntree)
trees.lay = addLayer(trees)
rm(trees)
###AddSurrogates###
trees.surr = addSurrogates(RF = RF,trees = trees.lay,s = s,Xdata = x, num.threads = num.threads)
trees = getTreeranger(RF = RF,ntree = ntree)
#' getsingletree
#'
#' This is an internal function
#'
#' @keywords internal
getsingletree=function(RF,k=1){
# here we use the treeInfo function of the ranger package to create extract the trees, in an earlier version this was done with a self implemented function
tree.ranger = ranger::treeInfo(RF,tree = k)
ktree=data.frame(as.numeric(tree.ranger$nodeID+1),
as.numeric(tree.ranger$leftChild+1),
as.numeric(tree.ranger$rightChild+1),
as.numeric(tree.ranger$splitvarID+1),
tree.ranger$splitval,
tree.ranger$terminal)
if (is.factor(ktree[,5])) {
ktree[,5] = as.character(levels(ktree[,5] ))[ktree[,5]]
}
ktree[,6] = as.numeric(ktree[,6] == FALSE)
for (i in 2:4) {
ktree[,i][is.na(ktree[,i])] = 0
}
colnames(ktree)=c("nodeID","leftdaughter","rightdaughter","splitvariable","splitpoint","status")
return(ktree)
}
trees=lapply(1:ntree,getsingletree,RF=RF)
colnames(ktree)=c("nodeID","leftdaughter","rightdaughter","splitvariable","splitpoint","status")
View(trees)
trees[[1]]
#'Get a list of structured trees for ranger
#'
#'This functions creates a list of trees for ranger objects similar as getTree function does for random Forest objects.
#'
#' @param RF random forest object created by ranger (with keep.inbag=TRUE)
#' @param ntree number of trees
#' @return a list with trees. Each row of the list elements corresponds to a node of the respective tree and the columns correspond to:
#' \itemize{
#' \item nodeID: ID of the respective node (important for left and right daughters in the next columns)
#' \item leftdaughter: ID of the left daughter of this node
#' \item rightdaughter: ID of the right daughter of this node
#' \item splitvariable: ID of the split variable
#' \item splitpoint: splitpoint of the split variable (for categorical variables this is a comma separated lists of values, representing the factor levels (in the original order) going to the right)
#' \item status: "0" for terminal and "1" for non-terminal
#' }
#' @export
getTreeranger=function(RF,ntree) {
trees=lapply(1:ntree,getsingletree,RF=RF)
return(trees)
}
#' getsingletree
#'
#' This is an internal function
#'
#' @keywords internal
getsingletree=function(RF,k=1){
# here we use the treeInfo function of the ranger package to create extract the trees, in an earlier version this was done with a self implemented function
tree.ranger = ranger::treeInfo(RF,tree = k)
ktree=data.frame(as.numeric(tree.ranger$nodeID+1),
as.numeric(tree.ranger$leftChild+1),
as.numeric(tree.ranger$rightChild+1),
as.numeric(tree.ranger$splitvarID+1),
tree.ranger$splitval,
tree.ranger$terminal)
if (is.factor(ktree[,5])) {
ktree[,5] = as.character(levels(ktree[,5] ))[ktree[,5]]
}
ktree[,6] = as.numeric(ktree[,6] == FALSE)
for (i in 2:4) {
ktree[,i][is.na(ktree[,i])] = 0
}
colnames(ktree)=c("nodeID","leftdaughter","rightdaughter","splitvariable","splitpoint","status")
return(ktree)
}
trees = getTreeranger(RF = RF,ntree = ntree)
trees.lay = addLayer(trees)
rm(trees)
###AddSurrogates###
trees.surr = addSurrogates(RF = RF,trees = trees.lay,s = s,Xdata = x, num.threads = num.threads)
library(SurrogateMinimalDepth)
# read data
data("SMD_example_data")
data = SMD_example_data
x = data[,2:ncol(data)]
y = data[,1]
ntree = 10
type = "regression"
s = 10
mtry = NULL
min.node.size = 1
num.threads = NULL
status = NULL
save.ranger = FALSE
create.forest = TRUE
forest = NULL
save.memory = FALSE
min.var.p = 200
p.t.sel = 0.01
p.t.rel = 0.01
select.var = TRUE
case.weights = NULL
variables = c("X1","X7")
candidates = colnames(x)[1:100]
variables = colnames(x)[1:10]
candidates = colnames(x)[1:100]
## check data
if (length(y) != nrow(x)) {
stop("length of y and number of rows in x are different")
}
if (any(is.na(x))) {
stop("missing values are not allowed")
}
allvariables = colnames(x)# extract variables names
nvar = length(allvariables)   # count number of variables
## set global parameters
if (is.null(mtry)) {
mtry = floor((nvar)^(3/4))
}
if (mtry == "sqrt") {
mtry = floor(sqrt(nvar))
}
if (mtry == "0.5") {
mtry = floor(0.5*(nvar))
}
if (mtry == "^3/4") {
mtry = floor((nvar)^(3/4))
}
if (is.null(s)) {
s = ceiling(nvar*0.01)
}
if (s > (nvar - 2)) {
s = nvar - 1
warning("s was set to the maximum number that is reasonable (variables-1) ")
}
if (type == "classification") {
y = as.factor(y)
if (length(levels(y)) > 15) {
stop("Too much classes defined, classification might be the wrong choice")
}
}
if (type == "regression" && class(y) == "factor") {
stop("use factor variable for y only for classification! ")
}
data = data.frame(y, x)
RF = ranger::ranger(data = data,dependent.variable.name = "y",num.trees = ntree,mtry = mtry,min.node.size = min.node.size,
keep.inbag = TRUE, num.threads = num.threads, case.weights = case.weights)
trees = getTreeranger(RF = RF,ntree = ntree)
trees.lay = addLayer(trees)
rm(trees)
###AddSurrogates###
trees.surr = addSurrogates(RF = RF,trees = trees.lay,s = s,Xdata = data[,-1], num.threads = num.threads)
rm(trees.lay)
forest = list(trees = trees.surr, allvariables = colnames(data[,-1]))
trees.surr
trees.lay
trees.lay = addLayer(trees)
trees = getTreeranger(RF = RF,ntree = ntree)
trees.lay = addLayer(trees)
trees.lay
trees[[1]]
test = trees[[1]]
test
class(test)
library(SurrogateMinimalDepth)
library(SurrogateMinimalDepth)
# read data
data("SMD_example_data")
data = SMD_example_data
x = data[,2:ncol(data)]
y = data[,1]
ntree = 10
type = "regression"
s = 10
mtry = NULL
min.node.size = 1
num.threads = NULL
status = NULL
save.ranger = FALSE
create.forest = TRUE
forest = NULL
save.memory = FALSE
min.var.p = 200
p.t.sel = 0.01
p.t.rel = 0.01
select.var = TRUE
case.weights = NULL
variables = c("X1","X7")
candidates = colnames(x)[1:100]
## check data
if (length(y) != nrow(x)) {
stop("length of y and number of rows in x are different")
}
if (any(is.na(x))) {
stop("missing values are not allowed")
}
variables = colnames(x)    # extract variables names
nvar = length(variables)   # count number of variables
## set global parameters
if (is.null(mtry)) {
mtry = floor((nvar)^(3/4))
}
if (mtry == "sqrt") {
mtry = floor(sqrt(nvar))
}
if (mtry == "0.5") {
mtry = floor(0.5*nvar)
}
if (mtry == "^3/4") {
mtry = floor((nvar)^(3/4))
}
if (is.null(s)) {
s = ceiling(nvar*0.01)
}
if (s > (nvar - 1)) {
s = nvar - 1
warning("s was set to the maximum number that is reasonable (variables-1) ")
}
if (type == "classification") {
y = as.factor(y)
if (length(levels(y)) > 15) {
stop("Too much classes defined, classification might be the wrong choice")
}
}
if (type == "regression" && class(y) == "factor") {
stop("use factor variable for y only for classification! ")
}
data = data.frame(y, x)
RF = ranger::ranger(data = data,dependent.variable.name = "y",num.trees = ntree,mtry = mtry,min.node.size = min.node.size,
keep.inbag = TRUE, num.threads = num.threads, case.weights = case.weights, respect.unordered.factors = "partition")
trees = getTreeranger(RF = RF,ntree = ntree)
trees = getTreeranger(RF = RF,ntree = ntree)
?var.select.smd
# read data
data("SMD_example_data")
# select variables (usually more trees are needed)
set.seed(42)
res = var.select.smd(x = SMD_example_data[,2:ncol(SMD_example_data)], y = SMD_example_data[,1],s = 10, ntree = 10)
res$var
# read data
data("SMD_example_data")
# select variables (usually more trees are needed)
set.seed(42)
res = var.select.smd(x = SMD_example_data[,2:ncol(SMD_example_data)], y = SMD_example_data[,1],s = 10, ntree = 10)
res$var
library(SurrogateMinimalDepth)
library(SurrogateMinimalDepth)
?var.select.smd
# read data
data("SMD_example_data")
# select variables (usually more trees are needed)
set.seed(42)
res = var.select.smd(x = SMD_example_data[,2:ncol(SMD_example_data)], y = SMD_example_data[,1],s = 10, ntree = 10)
res$var
>>>>>>> Stashed changes
library(devtools)
pacman::p_load(devtools)
devtools::check()
<<<<<<< HEAD
pacman::p_load(devtools, SurrogateMinimalDepth, labelled)
# for removing attr package labelled is neccesary
install_github("StephanSeifert/SurrogateMinimalDepth", ref = "SMD_0.2.1_LCJ")
=======
library("R.utils")
test = loadObject(file = "/home/stephan/Projekte/mutualginiimpurity/subprojects/03_ComparisonStudy_SimStudy3/data/gene_expression_array/simulation/classification/effects_-2_-1_-0.5_0.5_1_2/samples_200/causal.var_150/results/ntree_ 5000 _mtry_p34/mir/par_500_0.01/results_rep_1_data_set_1.RData")
library(SurrogateMinimalDepth)
# read data
data("SMD_example_data")
data = SMD_example_data
x = data[,2:ncol(data)]
y = data[,1]
ntree = 10
type = "regression"
s = 10
mtry = NULL
min.node.size = 1
num.threads = NULL
status = NULL
save.ranger = FALSE
create.forest = TRUE
forest = NULL
save.memory = FALSE
min.var.p = 200
p.t.sel = 0.01
p.t.rel = 0.01
select.var = TRUE
case.weights = NULL
variables = colnames(x)[1:9]
candidates = colnames(x)[1:100]
library(SurrogateMinimalDepth)
?var.select.smd
# read data
data("SMD_example_data")
# select variables (usually more trees are needed)
set.seed(42)
res = var.select.smd(x = SMD_example_data[,2:ncol(SMD_example_data)], y = SMD_example_data[,1],s = 10, ntree = 10)
res$var
library(SurrogateMinimalDepth)
res$var
library(SurrogateMinimalDepth)
# read data
data("SMD_example_data")
data = SMD_example_data
x = data[,2:ncol(data)]
y = data[,1]
ntree = 10
type = "regression"
s = 10
mtry = NULL
min.node.size = 1
num.threads = NULL
status = NULL
save.ranger = FALSE
create.forest = TRUE
forest = NULL
save.memory = FALSE
min.var.p = 200
p.t.sel = 0.01
p.t.rel = 0.01
select.var = TRUE
case.weights = NULL
variables = colnames(x)[1:9]
candidates = colnames(x)[1:100]
# read data
data("SMD_example_data")
# select variables (usually more trees are needed)
set.seed(42)
res = var.select.smd(x = SMD_example_data[,2:ncol(SMD_example_data)], y = SMD_example_data[,1],s = 10, ntree = 10)
res$var
library(SurrogateMinimalDepth)
?var.select.smd
# read data
data("SMD_example_data")
# select variables (usually more trees are needed)
set.seed(42)
res = var.select.smd(x = SMD_example_data[,2:ncol(SMD_example_data)], y = SMD_example_data[,1],s = 10, ntree = 10)
res$var
install_github("StephanSeifert/SurrogatMinimalDepth", ref = "SMD_0.2.1.LCJ")
library(devtools)
install_github("StephanSeifert/SurrogatMinimalDepth", ref = "SMD_0.2.1.LCJ")
install_github("StephanSeifert/SurrogateMinimalDepth", ref = "SMD_0.2.1.LCJ")
install_github("StephanSeifert/SurrogateMinimalDepth", ref = "SMD_0.2.1_LCJ")
# read data
data("SMD_example_data")
# select variables (usually more trees are needed)
set.seed(42)
res = var.select.smd(x = SMD_example_data[,2:ncol(SMD_example_data)], y = SMD_example_data[,1],s = 10, ntree = 10)
res$var
>>>>>>> 8a71999afb43d79f0113d47d9734af6e63de6c1d
